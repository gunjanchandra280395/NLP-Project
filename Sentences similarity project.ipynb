{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTLK Project: Analysis of Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to design an approach that makes use of Google and msn snippet in order to compute the semantic similarity between sentences. Given two sentences S1 and S2, the key is to input each of the sentences to the search engine and investigate the overlapping that may exist between the generated snippets. \n",
    "\n",
    "Seminar report date: 11.12.2018.\n",
    "Project delivery deadline: 7.1.2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDefine two sentences S1 and S2.\n",
    "\n",
    "  S1: What are snippets? S2: How to generatesnippets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tUse Google search API and msn search API to generate the first ten snippets associated to each sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tDesign and implement a similarity measure that computes the number of overlapping words between the total terms of the ten snippets associated to the first sentence S1 and the second sentence S2. \n",
    "\n",
    "    Hint: use loop for S1 snippets and S2 snippets similarity measurement. The measurement should be conducted between each snippets for each sentence S1 and S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5. Compare the result with sentence semantic similarity that you have seen in Lab2.\n",
    "    \n",
    "    Hint: in lab2, WordNet was used to calculate sentence semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "Similarity(\"Cats are beautiful animals.\", \"Dogs are awesome.\") = 0.3333333333333333\n",
      "0.2222222222222222\n",
      "Similarity(\"Dogs are awesome.\", \"Cats are beautiful animals.\") = 0.2222222222222222\n",
      "0.23650793650793647\n",
      "Similarity(\"Cats are beautiful animals.\", \"Some gorgeous creatures are felines.\") = 0.23650793650793647\n",
      "0.41798941798941797\n",
      "Similarity(\"Some gorgeous creatures are felines.\", \"Cats are beautiful animals.\") = 0.41798941798941797\n",
      "0.17777777777777778\n",
      "Similarity(\"Cats are beautiful animals.\", \"Dolphins are swimming mammals.\") = 0.17777777777777778\n",
      "0.14027777777777778\n",
      "Similarity(\"Dolphins are swimming mammals.\", \"Cats are beautiful animals.\") = 0.14027777777777778\n",
      "0.41203703703703703\n",
      "Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 0.41203703703703703\n",
      "0.41203703703703703\n",
      "Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 0.41203703703703703\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "#example\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    " \n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score, count = 0.0, 0\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    best_score = [0.0]\n",
    "    for ss1 in synsets1:\n",
    "        for ss2 in synsets2:\n",
    "            best1_score=ss1.path_similarity(ss2)\n",
    "        if best1_score is not None:\n",
    "            best_score.append(best1_score)\n",
    "        max1=max(best_score)\n",
    "        if best_score is not None:\n",
    "            score += max1\n",
    "        if max1 is not 0.0:\n",
    "            count += 1\n",
    "        best_score=[0.0]\n",
    "    print(score/count)      \n",
    "   \n",
    "    # Average the values\n",
    "    score /= count\n",
    "    return score\n",
    " \n",
    "sentences = [\n",
    "    \"Dogs are awesome.\",\n",
    "    \"Some gorgeous creatures are felines.\",\n",
    "    \"Dolphins are swimming mammals.\",\n",
    "    \"Cats are beautiful animals.\",\n",
    "]\n",
    " \n",
    "focus_sentence = \"Cats are beautiful animals.\"\n",
    " \n",
    "for sentence in sentences:\n",
    "    print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (focus_sentence, sentence, sentence_similarity(focus_sentence, sentence)))\n",
    "    print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (sentence, focus_sentence, sentence_similarity(sentence, focus_sentence)))\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Refine your code in order to expand the terms of each snippets to include all the hyponyms and hypernyms of the associated words by quering the WordNet database, and repeat the overlapping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Wikipedia based similarity.\n",
    "   Similarly, use Wikipedia dump files in order to design a program that search the Wikipedia documents for each Sentence. The similarity between the sentences is therefore measured as the number of common Wikipedia documents outputted by the queries (S1 and S2) over the total number of documents outputted by the two queries. Repeat the process of calculating the semantic similarity for your set of chosen academic examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use a publicly available database of your choice in order to test the usefulness of this similarity measure (Snippets and Wikipedia based similarity) and compare the results with some state of art measures mentioned in the literature employing your chosen publicly database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Design a simple GUI interface that allows you to demonstrate your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
